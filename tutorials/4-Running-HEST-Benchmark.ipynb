{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step instructions to run HEST-Benchmark\n",
    "\n",
    "This tutorial will guide you to:\n",
    "\n",
    "- **Reproduce** HEST-Benchmark results provided in the paper (Random Forest regression and Ridge regression models)\n",
    "- Benchmark your **own** model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Each task involves predicting the expression levels of the 50 most variable genes from 112×112 μm H&E-stained image patches centered on each spatial transcriptomics spot. The tasks are formulated as multivariate regression problems.\n",
    "\n",
    "| **Task ID** | **Oncotree** | **Number of Samples** | **Technology** | **Sample ID** |\n",
    "|-------------|--------------|-----------------------|----------------|---------------|\n",
    "| Task 1      | IDC          | 4                     | Xenium         | TENX95, TENX99, NCBI783, NCBI785      |\n",
    "| Task 2      | PRAD         | 23                    | Visium         | MEND139~MEND162      |\n",
    "| Task 3      | PAAD         | 3                     | Xenium         | TENX116, TENX126, TENX140      |\n",
    "| Task 4      | SKCM         | 2                     | Xenium         | TENX115, TENX117      |\n",
    "| Task 5      | COAD         | 6                     | Visium         | ZEN38, ZEN42, ZEN44, ZEN45, ZEN46, ZEN47      |\n",
    "| Task 6      | READ         | 4                     | Visium         | ZEN36, ZEN40, ZEN48, ZEN49      |\n",
    "| Task 7      | ccRCC        | 24                    | Visium         | INT1~INT24      |\n",
    "| Task 8      | HCC          | 2                     | Visium         | NCBI642, NCBI643      |\n",
    "| Task 9      | LUAD         | 2                     | Xenium         | TENX118, TENX141      |\n",
    "| Task 10     | IDC-LymphNode | 4                    | Visium         | NCBI681, NCBI682, NCBI683, NCBI684     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing HEST-Benchmark results \n",
    "\n",
    "- Ensure that HEST has been properly installed (see README, Installation)\n",
    "- Automatic download preprocessed patches, h5ad and gene targets  \n",
    "- Automatic download of publicly available patch encoders\n",
    "\n",
    "**Note:** Not all public foundation models can be shared due to licensing issues. We provide model-specific instructions that users can follow to access weights:\n",
    "\n",
    "#### CONCH installation (model + weights)\n",
    "\n",
    "1. Request access to the model weights from the Huggingface model page [here](https://huggingface.co/MahmoodLab/CONCH).\n",
    "\n",
    "2. Download the model weights (`pytorch_model.bin`) and place them in your `fm_v1` directory `fm_v1/conch_v1_official/pytorch_model.bin`\n",
    "\n",
    "3. Install the CONCH PyTorch model:\n",
    "\n",
    "```\n",
    "git clone https://github.com/mahmoodlab/CONCH.git\n",
    "cd CONCH\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "#### UNI installation (weights only)\n",
    "\n",
    "1. Request access to the model weights from the Huggingface model page [here](https://huggingface.co/MahmoodLab/UNI).\n",
    "\n",
    "2. Download the model weights (`pytorch_model.bin`) and place them in your `fm_v1` directory `fm_v1/uni_v1_official/pytorch_model.bin`\n",
    "\n",
    "\n",
    "#### GigaPath installation (weight only)\n",
    "\n",
    "1. Request access to the model weights from the Huggingface model page  [here](https://huggingface.co/prov-gigapath/prov-gigapath).\n",
    "2. Download the model weights (`prov-gigapath.bin`) and place them in your `fm_v1` directory `fm_v1/gigapath/pytorch_model.bin`\n",
    "\n",
    "\n",
    "#### Remedis (weights only)\n",
    "\n",
    "1. Request access to the model weights from the Huggingface model page  [here](https://physionet.org/content/medical-ai-research-foundation/1.0.0/).\n",
    "2. Download the model weights (`path-152x2-remedis-m_torch.pth`) and place them in your `fm_v1` directory `fm_v1/remedis/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/http/client.py\", line 289, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/http/client.py\", line 289, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/_snapshot_download.py\", line 164, in snapshot_download\n",
      "    repo_info = api.repo_info(repo_id=repo_id, repo_type=repo_type, revision=revision, token=token)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/hf_api.py\", line 2491, in repo_info\n",
      "    return method(\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/hf_api.py\", line 2363, in dataset_info\n",
      "    r = get_session().get(path, headers=headers, timeout=timeout, params=params)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/utils/_http.py\", line 66, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 08764655-62b3-44ca-b3f2-ae0329ce3755)')\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ssd/paul/ST-histology-loader/tutorials/../src/hest/bench/training/predict_expression.py\", line 409, in <module>\n",
      "    benchmark(args, None, None)\n",
      "  File \"/mnt/ssd/paul/ST-histology-loader/tutorials/../src/hest/bench/training/predict_expression.py\", line 360, in benchmark\n",
      "    snapshot_download(repo_id=\"MahmoodLab/hest-bench\", repo_type='dataset', local_dir=bench_fm_dir, allow_patterns=['fm_v1/*'])\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/fedshyvana/anaconda3/envs/cuml/lib/python3.9/site-packages/huggingface_hub/_snapshot_download.py\", line 236, in snapshot_download\n",
      "    raise LocalEntryNotFoundError(\n",
      "huggingface_hub.utils._errors.LocalEntryNotFoundError: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\npython ../src/hest/bench/training/predict_expression.py --config ../bench_config/bench_config.yaml\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython ../src/hest/bench/training/predict_expression.py --config ../bench_config/bench_config.yaml\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuml/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2474\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/cuml/lib/python3.9/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuml/lib/python3.9/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\npython ../src/hest/bench/training/predict_expression.py --config ../bench_config/bench_config.yaml\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python ../src/hest/bench/training/predict_expression.py --config ../bench_config/bench_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking your own model with HEST-Benchmark \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hest.bench import benchmark_encoder\n",
    "import torch\n",
    "\n",
    "PATH_TO_CONFIG = .. # path to `bench_config.yaml`\n",
    "model = .. # PyTorch model (torch.nn.Module)\n",
    "model_transforms = .. # transforms to apply during inference (torchvision.transforms.Compose)\n",
    "precision = torch.float32\n",
    "\n",
    "benchmark_encoder(        \n",
    "    model, \n",
    "    model_transforms,\n",
    "    precision,\n",
    "    PATH_TO_CONFIG\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
